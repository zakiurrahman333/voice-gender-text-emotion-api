{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d0565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5382ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: resampy in c:\\users\\abdul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abdul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from resampy) (1.26.4)\n",
      "Requirement already satisfied: numba>=0.53 in c:\\users\\abdul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from resampy) (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\abdul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.53->resampy) (0.44.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install resampy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00d567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples (augmented): 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal samples (augmented):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X))\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Normalize features\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m     74\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------- Feature Extraction ---------------------\n",
    "def extract_features(file_path, max_pad_len=174):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    if mfccs.shape[1] < max_pad_len:\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfccs = mfccs[:, :max_pad_len]\n",
    "    return mfccs\n",
    "\n",
    "# ------------------- Data Augmentation ---------------------\n",
    "def add_noise(data):\n",
    "    noise_amp = 0.005 * np.random.uniform() * np.amax(data)\n",
    "    return data + noise_amp * np.random.normal(size=data.shape[0])\n",
    "\n",
    "def pitch_shift(data, sr):\n",
    "    return librosa.effects.pitch_shift(data, sr, n_steps=random.choice([-2, -1, 1, 2]))\n",
    "\n",
    "def time_stretch(data):\n",
    "    rate = random.uniform(0.8, 1.2)\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def extract_augmented(file_path, max_pad_len=174):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    features = []\n",
    "    for func in [lambda x: x, add_noise, pitch_shift, time_stretch]:\n",
    "        try:\n",
    "            new_audio = func(audio) if func != time_stretch else func(audio)\n",
    "            mfcc = librosa.feature.mfcc(y=new_audio, sr=sample_rate, n_mfcc=40)\n",
    "            if mfcc.shape[1] < max_pad_len:\n",
    "                mfcc = np.pad(mfcc, ((0,0),(0,max_pad_len - mfcc.shape[1])), mode='constant')\n",
    "            else:\n",
    "                mfcc = mfcc[:, :max_pad_len]\n",
    "            features.append(mfcc)\n",
    "        except:\n",
    "            continue\n",
    "    return features\n",
    "\n",
    "# ------------------- Load Dataset ---------------------\n",
    "def load_dataset(path):\n",
    "    X, Y = [], []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                label = file.split('-')[2]\n",
    "                mfccs_list = extract_augmented(full_path)\n",
    "                for mfcc in mfccs_list:\n",
    "                    X.append(mfcc)\n",
    "                    Y.append(label)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# ------------------- Load & Preprocess ---------------------\n",
    "path = r'C:\\Users\\abdul\\Downloads\\audio-testing\\RAVDESS-AUDIO-DATASET'\n",
    "X, Y = load_dataset(path)\n",
    "print(\"Total samples (augmented):\", len(X))\n",
    "\n",
    "# Normalize features\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X_scaled.reshape(X.shape[0], 40, 174, 1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(Y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, stratify=y_categorical, random_state=42)\n",
    "\n",
    "# ------------------- CNN Model ---------------------\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(40, 174, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "# ------------------- Train ---------------------\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# ------------------- Evaluate ---------------------\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nâœ… Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# ------------------- Plot ---------------------\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ------------------- Predict External File ---------------------\n",
    "def predict_emotion(file_path):\n",
    "    mfcc = extract_features(file_path)\n",
    "    if mfcc is None:\n",
    "        return \"Could not extract\"\n",
    "    mfcc = scaler.transform(mfcc.reshape(1, -1))\n",
    "    mfcc = mfcc.reshape(1, 40, 174, 1)\n",
    "    prediction = model.predict(mfcc)\n",
    "    predicted_label = encoder.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Test your own audio\n",
    "external_path = r'C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\\AudioWAV\\1001_IEO_FEA_MD.wav'\n",
    "result = predict_emotion(external_path)\n",
    "print(\"ðŸŽ™ï¸ Predicted Emotion:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3989dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:36:32,376 - INFO - Loading audio files...\n",
      "2025-05-18 17:36:32,379 - INFO - Scanning folder: C:\\Users\\abdul\\Downloads\\audio-testing\\RAVDESS-AUDIO-DATASET\n",
      "2025-05-18 17:36:32,526 - INFO - Found 923 .wav files in C:\\Users\\abdul\\Downloads\\audio-testing\\RAVDESS-AUDIO-DATASET\n",
      "2025-05-18 17:36:32,532 - INFO - Scanning folder: C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\n",
      "2025-05-18 17:36:32,564 - INFO - Found 203 .wav files in C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\n",
      "2025-05-18 17:36:32,565 - INFO - Loaded 1126 audio files, skipped 0 files.\n",
      "2025-05-18 17:36:32,566 - INFO - Label distribution:\n",
      "2025-05-18 17:36:32,567 - INFO - neutral: 92\n",
      "2025-05-18 17:36:32,568 - INFO - calm: 128\n",
      "2025-05-18 17:36:32,569 - INFO - happy: 163\n",
      "2025-05-18 17:36:32,570 - INFO - sad: 158\n",
      "2025-05-18 17:36:32,571 - INFO - angry: 155\n",
      "2025-05-18 17:36:32,572 - INFO - fear: 155\n",
      "2025-05-18 17:36:32,575 - INFO - disgust: 155\n",
      "2025-05-18 17:36:32,576 - INFO - surprise: 120\n",
      "2025-05-18 17:36:32,613 - INFO - Training set size: 900, Validation set size: 226\n",
      "2025-05-18 17:36:32,615 - INFO - Converting to Huggingface Dataset...\n",
      "2025-05-18 17:36:32,649 - INFO - Loading feature extractor...\n",
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "2025-05-18 17:36:33,668 - INFO - Preprocessing training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeacceeb42f4445a82270bfb2924c6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838c8e6681784f768d220279c774bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:37:26,150 - INFO - Preprocessing validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f92f9913c44a9b8f2eb844552a0f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/226 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54acedf576f74f50bad37143af85616e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/226 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:37:35,227 - INFO - Training dataset size: 900, Validation dataset size: 226\n",
      "2025-05-18 17:37:35,241 - INFO - Loading model...\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-18 17:37:39,518 - INFO - Initializing trainer...\n",
      "2025-05-18 17:37:40,070 - INFO - Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1125/1125 1:33:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.831100</td>\n",
       "      <td>1.748951</td>\n",
       "      <td>0.278761</td>\n",
       "      <td>0.175670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.361300</td>\n",
       "      <td>1.407486</td>\n",
       "      <td>0.584071</td>\n",
       "      <td>0.560237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.057000</td>\n",
       "      <td>1.166153</td>\n",
       "      <td>0.646018</td>\n",
       "      <td>0.631255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.989300</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.725746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.752200</td>\n",
       "      <td>0.884539</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.743845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 19:11:50,018 - INFO - Training completed successfully.\n",
      "2025-05-18 19:11:54,626 - INFO - Model saved to ./results/final_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ----------- 1. Load data -------------------\n",
    "\n",
    "def get_label_from_filename(filename):\n",
    "    fname = filename.lower()\n",
    "    # RAVDESS: 03-01-05-01-01-01-01.wav\n",
    "    if filename.startswith(\"03-01-\"):\n",
    "        parts = filename.split(\"-\")\n",
    "        if len(parts) >= 3:\n",
    "            emotion_code = parts[2]\n",
    "            emotion_map = {\n",
    "                \"01\": \"neutral\",\n",
    "                \"02\": \"calm\",\n",
    "                \"03\": \"happy\",\n",
    "                \"04\": \"sad\",\n",
    "                \"05\": \"angry\",\n",
    "                \"06\": \"fear\",\n",
    "                \"07\": \"disgust\",\n",
    "                \"08\": \"surprise\"\n",
    "            }\n",
    "            label = emotion_map.get(emotion_code, \"unknown\")\n",
    "            if label == \"unknown\":\n",
    "                logger.debug(f\"Unknown RAVDESS emotion code {emotion_code} in {filename}\")\n",
    "            return label\n",
    "    # CREMA-D: 1001_DFA_ANG_XX.wav\n",
    "    if \"_ang_\" in fname:\n",
    "        return \"angry\"\n",
    "    elif \"_sad_\" in fname:\n",
    "        return \"sad\"\n",
    "    elif \"_hap_\" in fname:\n",
    "        return \"happy\"\n",
    "    elif \"_fea_\" in fname:\n",
    "        return \"fear\"\n",
    "    elif \"_dis_\" in fname:\n",
    "        return \"disgust\"\n",
    "    elif \"_neu_\" in fname:\n",
    "        return \"neutral\"\n",
    "    elif \"_sur_\" in fname:\n",
    "        return \"surprise\"\n",
    "    logger.debug(f\"Unknown label for file: {filename}\")\n",
    "    return \"unknown\"\n",
    "\n",
    "def load_data(folders):\n",
    "    audio_paths = []\n",
    "    labels = []\n",
    "    skipped_files = 0\n",
    "    for folder in folders:\n",
    "        folder_path = Path(folder)\n",
    "        if not folder_path.exists():\n",
    "            logger.error(f\"Folder not found: {folder}\")\n",
    "            continue\n",
    "        logger.info(f\"Scanning folder: {folder}\")\n",
    "        wav_files = list(folder_path.rglob(\"*.wav\"))\n",
    "        logger.info(f\"Found {len(wav_files)} .wav files in {folder}\")\n",
    "        for file_path in wav_files:\n",
    "            try:\n",
    "                label = get_label_from_filename(file_path.name)\n",
    "                if label != \"unknown\":\n",
    "                    audio_paths.append(str(file_path))\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    skipped_files += 1\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing file {file_path}: {e}\")\n",
    "                skipped_files += 1\n",
    "    logger.info(f\"Loaded {len(audio_paths)} audio files, skipped {skipped_files} files.\")\n",
    "    if len(audio_paths) < 100:\n",
    "        logger.warning(f\"Only {len(audio_paths)} audio files loaded. Expected more. Check dataset paths or file naming.\")\n",
    "    return audio_paths, labels\n",
    "\n",
    "# Define dataset paths\n",
    "folders = [\n",
    "    r\"C:\\Users\\abdul\\Downloads\\audio-testing\\RAVDESS-AUDIO-DATASET\",\n",
    "    r\"C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    logger.info(\"Loading audio files...\")\n",
    "    audio_paths, labels = load_data(folders)\n",
    "    \n",
    "    # Check label distribution\n",
    "    label_counts = Counter(labels)\n",
    "    logger.info(\"Label distribution:\")\n",
    "    for label, count in label_counts.items():\n",
    "        logger.info(f\"{label}: {count}\")\n",
    "    if len(label_counts) < 2:\n",
    "        raise ValueError(\"Insufficient unique labels for training.\")\n",
    "    if not audio_paths:\n",
    "        raise ValueError(\"No audio files loaded. Check dataset paths and file naming.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"path\": audio_paths, \"label\": labels})\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "# Save label encoder\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label_id\"], random_state=42)\n",
    "logger.info(f\"Training set size: {len(train_df)}, Validation set size: {len(val_df)}\")\n",
    "\n",
    "# ----------- 2. Huggingface Dataset and audio cast -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Converting to Huggingface Dataset...\")\n",
    "    train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "    train_ds = train_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "    val_ds = val_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating datasets: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 3. Feature Extractor and Preprocess -----------\n",
    "\n",
    "model_ckpt = \"facebook/wav2vec2-base\"\n",
    "try:\n",
    "    logger.info(\"Loading feature extractor...\")\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_ckpt)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading feature extractor: {e}\")\n",
    "    raise\n",
    "\n",
    "def preprocess(batch):\n",
    "    try:\n",
    "        audio = batch[\"path\"]\n",
    "        if audio[\"array\"] is None or len(audio[\"array\"]) == 0:\n",
    "            raise ValueError(\"Empty audio array\")\n",
    "        inputs = feature_extractor(\n",
    "            audio[\"array\"],\n",
    "            sampling_rate=audio[\"sampling_rate\"],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=16000 * 3,\n",
    "            truncation=True\n",
    "        )\n",
    "        batch[\"input_values\"] = inputs[\"input_values\"][0].numpy()\n",
    "        batch[\"attention_mask\"] = inputs.get(\"attention_mask\", torch.ones_like(inputs[\"input_values\"]))[0].numpy()\n",
    "        batch[\"labels\"] = batch[\"label_id\"]\n",
    "        return batch\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error preprocessing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    logger.info(\"Preprocessing training dataset...\")\n",
    "    train_ds = train_ds.map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"path\", \"label\", \"label_id\"],\n",
    "        batched=False,\n",
    "        load_from_cache_file=True\n",
    "    )\n",
    "    train_ds = train_ds.filter(lambda x: x[\"input_values\"] is not None)\n",
    "\n",
    "    logger.info(\"Preprocessing validation dataset...\")\n",
    "    val_ds = val_ds.map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"path\", \"label\", \"label_id\"],\n",
    "        batched=False,\n",
    "        load_from_cache_file=True\n",
    "    )\n",
    "    val_ds = val_ds.filter(lambda x: x[\"input_values\"] is not None)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during preprocessing: {e}\")\n",
    "    raise\n",
    "\n",
    "# Check if datasets are empty\n",
    "if len(train_ds) == 0 or len(val_ds) == 0:\n",
    "    raise ValueError(\"One or both datasets are empty after preprocessing.\")\n",
    "logger.info(f\"Training dataset size: {len(train_ds)}, Validation dataset size: {len(val_ds)}\")\n",
    "\n",
    "# ----------- 4. Model -----------\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "try:\n",
    "    logger.info(\"Loading model...\")\n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 5. Data collator -----------\n",
    "\n",
    "def collate_fn(batch):\n",
    "    try:\n",
    "        input_values = [torch.tensor(item[\"input_values\"], dtype=torch.float32) for item in batch]\n",
    "        attention_mask = [torch.tensor(item[\"attention_mask\"], dtype=torch.long) for item in batch]\n",
    "        labels = torch.tensor([item[\"labels\"] for item in batch], dtype=torch.long)\n",
    "\n",
    "        input_values_padded = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True)\n",
    "        attention_mask_padded = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True)\n",
    "\n",
    "        return {\n",
    "            \"input_values\": input_values_padded,\n",
    "            \"attention_mask\": attention_mask_padded,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data collation: {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------- 6. Compute metrics -----------\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# ----------- 7. Training arguments -----------\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=0,  # Disable multiprocessing to avoid worker crashes\n",
    ")\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "    logger.info(f\"GPU memory available: {gpu_memory:.2f} GB\")\n",
    "    if gpu_memory < 4:\n",
    "        logger.warning(\"Low GPU memory. Using batch size 2 instead of 4.\")\n",
    "        training_args.per_device_train_batch_size = 2\n",
    "        training_args.per_device_eval_batch_size = 2\n",
    "\n",
    "# ----------- 8. Trainer -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Initializing trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        processing_class=feature_extractor,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing trainer: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 9. Train -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    logger.info(\"Training completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during training: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./results/final_model\")\n",
    "logger.info(\"Model saved to ./results/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fa83bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 14:47:14,283 - INFO - Loading audio files...\n",
      "2025-05-19 14:47:14,298 - INFO - Scanning folder: C:\\Users\\abdul\\Downloads\\audio-testing\\IEMOCAP Dataset (IEMOCAP)\n",
      "2025-05-19 14:47:14,503 - INFO - Found 1756 .wav files in C:\\Users\\abdul\\Downloads\\audio-testing\\IEMOCAP Dataset\n",
      "2025-05-19 14:47:14,509 - INFO - Scanning folder: C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET (CREMA-D)\n",
      "2025-05-19 14:47:14,554 - INFO - Found 203 .wav files in C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\n",
      "2025-05-19 14:47:14,557 - INFO - Loaded 203 audio files, skipped 1756 files.\n",
      "2025-05-19 14:47:14,563 - INFO - Label distribution:\n",
      "2025-05-19 14:47:14,564 - INFO - angry: 35\n",
      "2025-05-19 14:47:14,565 - INFO - disgust: 35\n",
      "2025-05-19 14:47:14,566 - INFO - fear: 35\n",
      "2025-05-19 14:47:14,569 - INFO - happy: 35\n",
      "2025-05-19 14:47:14,571 - INFO - neutral: 28\n",
      "2025-05-19 14:47:14,572 - INFO - sad: 35\n",
      "2025-05-19 14:47:14,790 - INFO - Training set size: 162, Validation set size: 41\n",
      "2025-05-19 14:47:14,792 - INFO - Converting to Huggingface Dataset...\n",
      "2025-05-19 14:47:15,026 - INFO - Loading feature extractor...\n",
      "2025-05-19 14:47:16,069 - INFO - Preprocessing training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3a4b67100b4541b29234974405658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077aa5820fc24fd188f5bf982138051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 14:47:22,514 - INFO - Preprocessing validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f5bb42e1ad4420a1f0b931cf0905df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb43a06ba4b4c2892646cdd01436b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 14:47:23,984 - INFO - Training dataset size: 162, Validation dataset size: 41\n",
      "2025-05-19 14:47:23,985 - INFO - Loading model...\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-05-19 14:47:25,814 - INFO - Initializing trainer...\n",
      "2025-05-19 14:47:26,089 - INFO - Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [205/205 19:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.796700</td>\n",
       "      <td>1.777135</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.134516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.726900</td>\n",
       "      <td>1.724994</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.201011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.693100</td>\n",
       "      <td>1.707531</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.247083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>1.661394</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.208051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.686600</td>\n",
       "      <td>1.662611</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.211992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 15:07:01,780 - INFO - Training completed successfully.\n",
      "2025-05-19 15:07:07,640 - INFO - Model and feature extractor saved to ./results/final_model\n",
      "2025-05-19 15:07:10,033 - INFO - Predicted emotion: happy (Confidence: 0.18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: happy, Confidence: 0.18\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset, Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    HubertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ----------- 1. Data Augmentation Function -----------\n",
    "\n",
    "def add_noise(audio, noise_factor=0.005):\n",
    "    \"\"\"Add random white noise to audio to simulate real-world conditions.\"\"\"\n",
    "    try:\n",
    "        noise = torch.randn_like(torch.tensor(audio, dtype=torch.float32)) * noise_factor\n",
    "        noisy_audio = audio + noise.numpy()\n",
    "        # Clip to prevent distortion\n",
    "        noisy_audio = np.clip(noisy_audio, -1.0, 1.0)\n",
    "        return noisy_audio\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error adding noise: {e}\")\n",
    "        return audio\n",
    "\n",
    "# ----------- 2. Load data -------------------\n",
    "\n",
    "def get_label_from_filename(filename, dataset_type):\n",
    "    fname = filename.lower()\n",
    "    if dataset_type == \"IEMOCAP\":\n",
    "        label_map = {\n",
    "            \"hap\": \"happy\",\n",
    "            \"sad\": \"sad\",\n",
    "            \"ang\": \"angry\",\n",
    "            \"neu\": \"neutral\",\n",
    "            \"exc\": \"excited\",\n",
    "            \"fru\": \"frustrated\"\n",
    "        }\n",
    "        for key, value in label_map.items():\n",
    "            if f\"_{key}\" in fname:\n",
    "                return value\n",
    "        logger.debug(f\"Unknown IEMOCAP label for file: {filename}\")\n",
    "        return \"unknown\"\n",
    "    elif dataset_type == \"CREMA-D\":\n",
    "        if \"_ang_\" in fname:\n",
    "            return \"angry\"\n",
    "        elif \"_sad_\" in fname:\n",
    "            return \"sad\"\n",
    "        elif \"_hap_\" in fname:\n",
    "            return \"happy\"\n",
    "        elif \"_fea_\" in fname:\n",
    "            return \"fear\"\n",
    "        elif \"_dis_\" in fname:\n",
    "            return \"disgust\"\n",
    "        elif \"_neu_\" in fname:\n",
    "            return \"neutral\"\n",
    "        logger.debug(f\"Unknown CREMA-D label for file: {filename}\")\n",
    "        return \"unknown\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def load_data(folders):\n",
    "    audio_paths = []\n",
    "    labels = []\n",
    "    skipped_files = 0\n",
    "    for folder in folders:\n",
    "        folder_path = Path(folder[\"path\"])\n",
    "        dataset_type = folder[\"type\"]\n",
    "        if not folder_path.exists():\n",
    "            logger.error(f\"Folder not found: {folder_path}\")\n",
    "            continue\n",
    "        logger.info(f\"Scanning folder: {folder_path} ({dataset_type})\")\n",
    "        wav_files = list(folder_path.rglob(\"*.wav\"))\n",
    "        logger.info(f\"Found {len(wav_files)} .wav files in {folder_path}\")\n",
    "        for file_path in wav_files:\n",
    "            try:\n",
    "                label = get_label_from_filename(file_path.name, dataset_type)\n",
    "                if label != \"unknown\":\n",
    "                    audio_paths.append(str(file_path))\n",
    "                    labels.append(label)\n",
    "                else:\n",
    "                    skipped_files += 1\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing file {file_path}: {e}\")\n",
    "                skipped_files += 1\n",
    "    logger.info(f\"Loaded {len(audio_paths)} audio files, skipped {skipped_files} files.\")\n",
    "    if len(audio_paths) < 100:\n",
    "        logger.warning(f\"Only {len(audio_paths)} audio files loaded. Expected more. Check dataset paths or file naming.\")\n",
    "    return audio_paths, labels\n",
    "\n",
    "# Define dataset paths\n",
    "folders = [\n",
    "    {\"path\": r\"C:\\Users\\abdul\\Downloads\\audio-testing\\IEMOCAP Dataset\", \"type\": \"IEMOCAP\"},\n",
    "    {\"path\": r\"C:\\Users\\abdul\\Downloads\\audio-testing\\CREMA-D -AUDIO-DATASET\", \"type\": \"CREMA-D\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    logger.info(\"Loading audio files...\")\n",
    "    audio_paths, labels = load_data(folders)\n",
    "    \n",
    "    # Check label distribution\n",
    "    label_counts = Counter(labels)\n",
    "    logger.info(\"Label distribution:\")\n",
    "    for label, count in label_counts.items():\n",
    "        logger.info(f\"{label}: {count}\")\n",
    "    if len(label_counts) < 2:\n",
    "        raise ValueError(\"Insufficient unique labels for training.\")\n",
    "    if not audio_paths:\n",
    "        raise ValueError(\"No audio files loaded. Check dataset paths and file naming.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"path\": audio_paths, \"label\": labels})\n",
    "\n",
    "# Standardize labels\n",
    "df[\"label\"] = df[\"label\"].replace({\"excited\": \"happy\", \"frustrated\": \"angry\"})\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df[\"label_id\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "# Save label encoder\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"label_id\"], random_state=42)\n",
    "logger.info(f\"Training set size: {len(train_df)}, Validation set size: {len(val_df)}\")\n",
    "\n",
    "# ----------- 3. Huggingface Dataset and audio cast -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Converting to Huggingface Dataset...\")\n",
    "    train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_ds = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "    train_ds = train_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "    val_ds = val_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating datasets: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 4. Feature Extractor and Preprocess -----------\n",
    "\n",
    "model_ckpt = \"facebook/hubert-base-ls960\"\n",
    "try:\n",
    "    logger.info(\"Loading feature extractor...\")\n",
    "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_ckpt)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading feature extractor: {e}\")\n",
    "    raise\n",
    "\n",
    "def preprocess(batch):\n",
    "    try:\n",
    "        audio = batch[\"path\"]\n",
    "        if audio[\"array\"] is None or len(audio[\"array\"]) == 0:\n",
    "            raise ValueError(\"Empty audio array\")\n",
    "        # Apply augmentation to training data with 50% probability\n",
    "        if np.random.rand() < 0.5 and \"label_id\" in batch:  # Ensure it's training data\n",
    "            audio_array = add_noise(audio[\"array\"])\n",
    "        else:\n",
    "            audio_array = audio[\"array\"]\n",
    "        inputs = feature_extractor(\n",
    "            audio_array,\n",
    "            sampling_rate=audio[\"sampling_rate\"],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=16000 * 5,\n",
    "            truncation=True\n",
    "        )\n",
    "        batch[\"input_values\"] = inputs[\"input_values\"][0].numpy()\n",
    "        batch[\"attention_mask\"] = inputs.get(\"attention_mask\", torch.ones_like(inputs[\"input_values\"]))[0].numpy()\n",
    "        batch[\"labels\"] = batch[\"label_id\"]\n",
    "        return batch\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error preprocessing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    logger.info(\"Preprocessing training dataset...\")\n",
    "    train_ds = train_ds.map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"path\", \"label\", \"label_id\"],\n",
    "        batched=False,\n",
    "        load_from_cache_file=True\n",
    "    )\n",
    "    train_ds = train_ds.filter(lambda x: x[\"input_values\"] is not None)\n",
    "\n",
    "    logger.info(\"Preprocessing validation dataset...\")\n",
    "    val_ds = val_ds.map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"path\", \"label\", \"label_id\"],\n",
    "        batched=False,\n",
    "        load_from_cache_file=True\n",
    "    )\n",
    "    val_ds = val_ds.filter(lambda x: x[\"input_values\"] is not None)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during preprocessing: {e}\")\n",
    "    raise\n",
    "\n",
    "# Check if datasets are empty\n",
    "if len(train_ds) == 0 or len(val_ds) == 0:\n",
    "    raise ValueError(\"One or both datasets are empty after preprocessing.\")\n",
    "logger.info(f\"Training dataset size: {len(train_ds)}, Validation dataset size: {len(val_ds)}\")\n",
    "\n",
    "# ----------- 5. Model -----------\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "try:\n",
    "    logger.info(\"Loading model...\")\n",
    "    model = HubertForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 6. Data collator -----------\n",
    "\n",
    "def collate_fn(batch):\n",
    "    try:\n",
    "        input_values = [torch.tensor(item[\"input_values\"], dtype=torch.float32) for item in batch]\n",
    "        attention_mask = [torch.tensor(item[\"attention_mask\"], dtype=torch.long) for item in batch]\n",
    "        labels = torch.tensor([item[\"labels\"] for item in batch], dtype=torch.long)\n",
    "\n",
    "        input_values_padded = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True)\n",
    "        attention_mask_padded = torch.nn.utils.rnn.pad_sequence(attention_mask, batch_first=True)\n",
    "\n",
    "        return {\n",
    "            \"input_values\": input_values_padded,\n",
    "            \"attention_mask\": attention_mask_padded,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data collation: {e}\")\n",
    "        raise\n",
    "\n",
    "# ----------- 7. Compute metrics -----------\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "# ----------- 8. Training arguments -----------\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=0,\n",
    ")\n",
    "\n",
    "# Check GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "    logger.info(f\"GPU memory available: {gpu_memory:.2f} GB\")\n",
    "    if gpu_memory < 4:\n",
    "        logger.warning(\"Low GPU memory. Using batch size 2 instead of 4.\")\n",
    "        training_args.per_device_train_batch_size = 2\n",
    "        training_args.per_device_eval_batch_size = 2\n",
    "\n",
    "# ----------- 9. Trainer -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Initializing trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        processing_class=feature_extractor,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing trainer: {e}\")\n",
    "    raise\n",
    "\n",
    "# ----------- 10. Train -----------\n",
    "\n",
    "try:\n",
    "    logger.info(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    logger.info(\"Training completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during training: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save the model and feature extractor\n",
    "trainer.save_model(\"./results/final_model\")\n",
    "feature_extractor.save_pretrained(\"./results/final_model\")\n",
    "logger.info(\"Model and feature extractor saved to ./results/final_model\")\n",
    "\n",
    "# ----------- 11. Prediction Function for External Audio -----------\n",
    "\n",
    "def predict_emotion(audio_file_path, model_path=\"./results/final_model\"):\n",
    "    try:\n",
    "        # Load model and feature extractor\n",
    "        model = HubertForSequenceClassification.from_pretrained(model_path)\n",
    "        feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_path)\n",
    "        with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "            le = pickle.load(f)\n",
    "\n",
    "        # Load and preprocess audio\n",
    "        waveform, sample_rate = torchaudio.load(audio_file_path)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        waveform = waveform.squeeze().numpy()\n",
    "\n",
    "        inputs = feature_extractor(\n",
    "            waveform,\n",
    "            sampling_rate=16000,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            max_length=16000 * 5,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Move to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Predict\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "            predicted_label = le.inverse_transform([predicted_id])[0]\n",
    "            confidence = probabilities[0][predicted_id].item()\n",
    "\n",
    "        logger.info(f\"Predicted emotion: {predicted_label} (Confidence: {confidence:.2f})\")\n",
    "        return predicted_label, confidence\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error predicting emotion for {audio_file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with path to an external .wav file\n",
    "    test_audio = r\"C:\\Users\\abdul\\Downloads\\audio-testing\\hap.wav\"\n",
    "    if Path(test_audio).exists():\n",
    "        label, confidence = predict_emotion(test_audio)\n",
    "        if label:\n",
    "            print(f\"Emotion: {label}, Confidence: {confidence:.2f}\")\n",
    "    else:\n",
    "        logger.warning(f\"Test audio file {test_audio} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a5a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0519 15:15:06.256000 40036 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion: joy (confidence: 0.51)\n",
      "Predicted emotion: joy (confidence: 0.51)\n",
      "Predicted emotion: anger (confidence: 0.99)\n",
      "Predicted emotion: anger (confidence: 0.99)\n",
      "Predicted emotion: joy (confidence: 0.46)\n",
      "Predicted emotion: fear (confidence: 0.66)\n",
      "Predicted emotion: joy (confidence: 0.52)\n",
      "Predicted emotion: anger (confidence: 0.47)\n",
      "Predicted emotion: joy (confidence: 1.00)\n",
      "Predicted emotion: joy (confidence: 1.00)\n",
      "Predicted emotion: joy (confidence: 0.53)\n",
      "Predicted emotion: anger (confidence: 0.85)\n",
      "Predicted emotion: anger (confidence: 0.81)\n",
      "Predicted emotion: joy (confidence: 0.87)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pretrained emotion classification model\n",
    "# (this is a small/distilbert model fine-tuned for emotion classification)\n",
    "emotion_classifier = pipeline(\"text-classification\", \n",
    "                              model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "                              return_all_scores=True)\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    results = emotion_classifier(text)[0]  # list of dicts: label + score\n",
    "    # Find the emotion with the highest score\n",
    "    best = max(results, key=lambda x: x['score'])\n",
    "    return best['label'], best['score']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        transcript = input(\"Enter transcript text (or 'exit' to quit): \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        emotion, score = predict_emotion_from_text(transcript)\n",
    "        print(f\"Predicted emotion: {emotion} (confidence: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 10:30:25.773000 30580 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion: joy (confidence: 0.99)\n",
      "Predicted emotion: joy (confidence: 0.99)\n",
      "Predicted emotion: anger (confidence: 0.37)\n",
      "Predicted emotion: joy (confidence: 0.99)\n",
      "Predicted emotion: joy (confidence: 0.99)\n",
      "Predicted emotion: anger (confidence: 0.88)\n",
      "Predicted emotion: anger (confidence: 0.86)\n",
      "Predicted emotion: joy (confidence: 0.68)\n",
      "Predicted emotion: joy (confidence: 0.68)\n",
      "Predicted emotion: love (confidence: 0.83)\n",
      "Predicted emotion: anger (confidence: 0.47)\n",
      "Predicted emotion: anger (confidence: 0.56)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a model with wider emotion labels\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"nateraw/bert-base-uncased-emotion\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    results = emotion_classifier(text)[0]\n",
    "    best = max(results, key=lambda x: x['score'])\n",
    "    return best['label'], best['score']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        transcript = input(\"Enter transcript text (or 'exit' to quit): \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        emotion, score = predict_emotion_from_text(transcript)\n",
    "        print(f\"Predicted emotion: {emotion} (confidence: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3106783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 10:34:08.384000 13168 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predicted emotion: Anger (confidence: 0.47)\n",
      "âœ… Predicted emotion: Joy (confidence: 0.56)\n",
      "âœ… Predicted emotion: Joy (confidence: 0.99)\n",
      "âœ… Predicted emotion: Joy (confidence: 0.99)\n",
      "âœ… Predicted emotion: Joy (confidence: 0.87)\n",
      "âœ… Predicted emotion: Anger (confidence: 0.68)\n",
      "âœ… Predicted emotion: Joy (confidence: 0.72)\n",
      "âœ… Predicted emotion: Anger (confidence: 0.72)\n",
      "âœ… Predicted emotion: Anger (confidence: 0.36)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load both emotion classifiers\n",
    "model_1 = pipeline(\"text-classification\",\n",
    "                   model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
    "                   return_all_scores=True)\n",
    "\n",
    "model_2 = pipeline(\"text-classification\",\n",
    "                   model=\"nateraw/bert-base-uncased-emotion\",\n",
    "                   return_all_scores=True)\n",
    "\n",
    "def merge_scores(results):\n",
    "    \"\"\"Helper to normalize and merge model output scores into one dict.\"\"\"\n",
    "    merged = {}\n",
    "    for res in results:\n",
    "        for item in res:\n",
    "            label = item[\"label\"].lower()\n",
    "            score = item[\"score\"]\n",
    "            merged[label] = merged.get(label, 0) + score\n",
    "    return merged\n",
    "\n",
    "def predict_ensemble_emotion(text):\n",
    "    results_1 = model_1(text)[0]\n",
    "    results_2 = model_2(text)[0]\n",
    "    \n",
    "    # Merge scores from both models\n",
    "    merged_scores = merge_scores([results_1, results_2])\n",
    "    \n",
    "    # Pick the emotion with the highest combined score\n",
    "    best_label = max(merged_scores, key=merged_scores.get)\n",
    "    confidence = merged_scores[best_label] / 2  # Average confidence across 2 models\n",
    "\n",
    "    return best_label.capitalize(), confidence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        transcript = input(\"Enter transcript text (or 'exit' to quit): \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        emotion, score = predict_ensemble_emotion(transcript)\n",
    "        print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 10:46:42.728000 41712 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion detection with example sentences (type 'exit' to quit).\n",
      "Enter your own transcript or press Enter to test predefined sentences.\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Admiration (confidence: 0.71)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Curiosity (confidence: 0.63)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Excitement (confidence: 0.82)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Confusion (confidence: 0.52)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Disappointment (confidence: 0.42)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Curiosity (confidence: 0.53)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Curiosity (confidence: 0.53)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the RoBERTa-based emotion classifier\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"SamLowe/roberta-base-go_emotions\",\n",
    "    top_k=None,  # Replace return_all_scores=True\n",
    "    truncation=True,  # Enable truncation directly\n",
    "    max_length=512  # Set max_length directly\n",
    ")\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    \"\"\"\n",
    "    Predict emotion from input text using the RoBERTa GoEmotions model.\n",
    "    Returns the dominant emotion and its confidence score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure text is not empty\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Input text is empty\")\n",
    "        \n",
    "        # Get model predictions\n",
    "        results = emotion_classifier(text)[0]\n",
    "        # Find the emotion with the highest score\n",
    "        best = max(results, key=lambda x: x['score'])\n",
    "        emotion = best['label'].capitalize()\n",
    "        score = best['score']\n",
    "        return emotion, score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example sentences to test\n",
    "    test_sentences = [\n",
    "        \"I donâ€™t care how good you are, just get it done!\",\n",
    "        \"What is machine learning?\",\n",
    "        \"Iâ€™m so excited for the concert tonight!\",\n",
    "        \"Why isnâ€™t this working properly?\",\n",
    "        \"Iâ€™m feeling really down today.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing emotion detection with example sentences (type 'exit' to quit).\")\n",
    "    print(\"Enter your own transcript or press Enter to test predefined sentences.\")\n",
    "    \n",
    "    while True:\n",
    "        transcript = input(\"Transcript: \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        if not transcript.strip():\n",
    "            # If no input, test predefined sentences\n",
    "            print(\"\\nTesting predefined sentences:\")\n",
    "            for sentence in test_sentences:\n",
    "                emotion, score = predict_emotion_from_text(sentence)\n",
    "                print(f\"Sentence: '{sentence}'\")\n",
    "                print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "        else:\n",
    "            # Process user input\n",
    "            emotion, score = predict_emotion_from_text(transcript)\n",
    "            print(f\"Sentence: '{transcript}'\")\n",
    "            print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8451898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 10:50:22.884000 33364 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion: neutral (confidence: 0.55)\n",
      "Predicted emotion: anger (confidence: 0.87)\n",
      "Predicted emotion: neutral (confidence: 0.78)\n",
      "Predicted emotion: joy (confidence: 0.93)\n",
      "Predicted emotion: surprise (confidence: 0.30)\n",
      "Predicted emotion: sadness (confidence: 0.99)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                      model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                      return_all_scores=True)\n",
    "\n",
    "def predict_emotion(text):\n",
    "    results = classifier(text)[0]\n",
    "    best = max(results, key=lambda x: x[\"score\"])\n",
    "    return best[\"label\"], best[\"score\"]\n",
    "\n",
    "while True:\n",
    "    sentence = input(\"Enter sentence: \")\n",
    "    if sentence.lower() == \"exit\":\n",
    "        break\n",
    "    emotion, score = predict_emotion(sentence)\n",
    "    print(f\"Predicted emotion: {emotion} (confidence: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e5699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 10:54:33.505000 12024 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12f641d0824573b62479d585e3f05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abdul\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-emotion. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e58222870c24fd4a4ef9dbbb37efbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fe1f4ae5e7489bbb0a36ce24af512f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c15bfa9d4ca437eba2d0047c07364ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2c53aefb3a4759a39e9f2771cb42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4856c4cb8db24efeb916534af19da48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion detection with example sentences (type 'exit' to quit).\n",
      "Enter your own transcript or press Enter to test predefined sentences.\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.89)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'what is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Are you sure you get it right this time'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.51)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.89)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Are you sure you get it right this time???'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.68)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.89)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Are you serious '\n",
      "âœ… Predicted emotion: Joy (confidence: 0.64)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.89)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that '\n",
      "âœ… Predicted emotion: Joy (confidence: 0.98)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.89)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.98)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load the Twitter RoBERTa-based emotion classifier\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    top_k=None,  # Get scores for all labels\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"  # Use PyTorch to avoid TensorFlow warnings\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean WebRTC transcription text by removing filler words, extra spaces, and normalizing.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\b(um|uh|like|you know)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    # Remove excessive punctuation that might confuse the model\n",
    "    text = re.sub(r'[.!?]{2,}', '.', text)\n",
    "    return text\n",
    "\n",
    "def is_neutral_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for neutral queries (e.g., informational questions).\n",
    "    Returns True if the sentence is likely neutral.\n",
    "    \"\"\"\n",
    "    neutral_patterns = [\n",
    "        r'^(what|how|when|where|why|can you|could you|tell me|is it).*?\\?$',\n",
    "        r'^(please|could you|would you).*?(schedule|set|find|look up|tell me).*'\n",
    "    ]\n",
    "    text = text.lower().strip()\n",
    "    return any(re.match(pattern, text) for pattern in neutral_patterns)\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    \"\"\"\n",
    "    Predict emotion from input text using the Twitter RoBERTa model.\n",
    "    Includes rule-based neutral fallback. Returns the dominant emotion and its confidence score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the input text\n",
    "        text = clean_text(text)\n",
    "        if not text:\n",
    "            raise ValueError(\"Input text is empty after cleaning\")\n",
    "\n",
    "        # Check for neutral queries first\n",
    "        if is_neutral_query(text):\n",
    "            return \"Neutral\", 0.9  # High confidence for rule-based neutral\n",
    "\n",
    "        # Get model predictions\n",
    "        results = emotion_classifier(text)[0]\n",
    "        # Find the emotion with the highest score\n",
    "        best = max(results, key=lambda x: x['score'])\n",
    "        emotion = best['label'].replace('emotion:', '').capitalize()  # Clean label\n",
    "        score = best['score']\n",
    "\n",
    "        # Fallback to Neutral if confidence is low\n",
    "        if score < 0.6:\n",
    "            return \"Neutral\", score\n",
    "\n",
    "        return emotion, score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test sentences from your output\n",
    "    test_sentences = [\n",
    "        \"I donâ€™t care how good you are, just get it done!\",\n",
    "        \"What is machine learning?\",\n",
    "        \"Iâ€™m so excited for the concert tonight!\",\n",
    "        \"Why isnâ€™t this working properly?\",\n",
    "        \"Iâ€™m feeling really down today.\",\n",
    "        \"Could you please schedule a meeting for next week?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing emotion detection with example sentences (type 'exit' to quit).\")\n",
    "    print(\"Enter your own transcript or press Enter to test predefined sentences.\")\n",
    "    \n",
    "    while True:\n",
    "        transcript = input(\"Transcript: \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        if not transcript.strip():\n",
    "            # Test predefined sentences\n",
    "            print(\"\\nTesting predefined sentences:\")\n",
    "            for sentence in test_sentences:\n",
    "                emotion, score = predict_emotion_from_text(sentence)\n",
    "                print(f\"Sentence: '{sentence}'\")\n",
    "                print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "        else:\n",
    "            # Process user input\n",
    "            emotion, score = predict_emotion_from_text(transcript)\n",
    "            print(f\"Sentence: '{transcript}'\")\n",
    "            print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a4c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 11:19:17.446000 27856 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion detection with example sentences (type 'exit' to quit).\n",
      "Enter your own transcript or press Enter to test predefined sentences.\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'I canâ€™t believe you messed this up, fix it now!'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'feel so lost, nothing makes sense anymore'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'You gotta be kidding me, this is the worst service ever!'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.98)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'Hey, can you set an alarm for 7 AM tomorrow?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.40)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.87)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.97)\n",
      "\n",
      "Sentence: 'Hey, can you set an alarm for 7 AM tomorrow?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load the Twitter RoBERTa-based emotion classifier\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    top_k=None,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean WebRTC transcription text by adding punctuation, removing filler words, and normalizing.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\b(um|uh|like|you know)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    # Add punctuation for run-on sentences\n",
    "    text = re.sub(r'\\b(are you serious|come on|i did not|this is ridiculous|what the)\\b', r'\\1.', text)\n",
    "    text = re.sub(r'\\b(this what|what you)\\b', r'\\1,', text)\n",
    "    text = text.replace(' i ', ' I ')\n",
    "    if not text.endswith('.'):\n",
    "        text += '.'\n",
    "    return text\n",
    "\n",
    "def is_neutral_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for neutral queries, excluding emotionally charged questions.\n",
    "    \"\"\"\n",
    "    neutral_patterns = [\n",
    "        r'^(what|how|when|where|can you|could you|tell me|is it).*?\\?$',\n",
    "        r'^(please|could you|would you).*?(schedule|set|find|look up|tell me).*'\n",
    "    ]\n",
    "    negative_words = ['not', 'isn\\'t', 'doesn\\'t', 'won\\'t', 'can\\'t', 'serious', 'ridiculous']\n",
    "    technical_terms = ['machine learning', 'deep learning', 'artificial intelligence', 'data science']\n",
    "    text = text.lower().strip()\n",
    "    # Mark as neutral if it contains technical terms\n",
    "    if any(term in text for term in technical_terms):\n",
    "        return True\n",
    "    # Exclude questions with negative/emotional words\n",
    "    if any(word in text for word in negative_words):\n",
    "        return False\n",
    "    return any(re.match(pattern, text) for pattern in neutral_patterns)\n",
    "\n",
    "def boost_anger_score(text, results):\n",
    "    \"\"\"\n",
    "    Boost anger score for sentences with anger-related keywords/phrases.\n",
    "    \"\"\"\n",
    "    anger_keywords = [\n",
    "        'are you serious', 'come on', 'i did not expect', 'this is ridiculous', \n",
    "        'what the', 'this what', 'not expected', 'you kidding'\n",
    "    ]\n",
    "    text = text.lower().strip()\n",
    "    if any(keyword in text for keyword in anger_keywords):\n",
    "        for result in results:\n",
    "            if result['label'] == 'emotion:anger':\n",
    "                result['score'] = min(result['score'] * 2.0, 1.0)  # Double anger score\n",
    "    return results\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    \"\"\"\n",
    "    Predict emotion from input text using the Twitter RoBERTa model with neutral fallback and anger boost.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the input text\n",
    "        text = clean_text(text)\n",
    "        if not text:\n",
    "            raise ValueError(\"Input text is empty after cleaning\")\n",
    "\n",
    "        # Check for neutral queries\n",
    "        if is_neutral_query(text):\n",
    "            return \"Neutral\", 0.95  # Higher confidence for neutral\n",
    "\n",
    "        # Get model predictions and boost anger if applicable\n",
    "        results = emotion_classifier(text)[0]\n",
    "        results = boost_anger_score(text, results)\n",
    "        \n",
    "        # Find the emotion with the highest score\n",
    "        best = max(results, key=lambda x: x['score'])\n",
    "        emotion = best['label'].replace('emotion:', '').capitalize()\n",
    "        score = best['score']\n",
    "\n",
    "        # Fallback to Neutral if confidence is low\n",
    "        if score < 0.7:\n",
    "            return \"Neutral\", score\n",
    "\n",
    "        return emotion, score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test sentences\n",
    "    test_sentences = [\n",
    "        \"I donâ€™t care how good you are, just get it done!\",\n",
    "        \"What is machine learning?\",\n",
    "        \"Iâ€™m so excited for the concert tonight!\",\n",
    "        \"Why isnâ€™t this working properly?\",\n",
    "        \"Iâ€™m feeling really down today.\",\n",
    "        \"Could you please schedule a meeting for next week?\",\n",
    "        \"What is deep learning?\",\n",
    "        \"Are you serious this what you are giving me come on i did not expected that from you\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing emotion detection with example sentences (type 'exit' to quit).\")\n",
    "    print(\"Enter your own transcript or press Enter to test predefined sentences.\")\n",
    "    \n",
    "    while True:\n",
    "        transcript = input(\"Transcript: \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        if not transcript.strip():\n",
    "            print(\"\\nTesting predefined sentences:\")\n",
    "            for sentence in test_sentences:\n",
    "                emotion, score = predict_emotion_from_text(sentence)\n",
    "                print(f\"Sentence: '{sentence}'\")\n",
    "                print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "        else:\n",
    "            emotion, score = predict_emotion_from_text(transcript)\n",
    "            print(f\"Sentence: '{transcript}'\")\n",
    "            print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d56c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 11:25:25.066000 31080 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion detection with example sentences (type 'exit' to quit).\n",
      "Enter your own transcript or press Enter to test predefined sentences.\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.92)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'This is absolutely unacceptable, do better!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Can you explain how neural networks work?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m having the worst day ever, nothing is going right.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.87)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'What the heck is wrong with this thing, itâ€™s broken again!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Tell me about the latest AI advancements.'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.47)\n",
      "\n",
      "Sentence: 'I canâ€™t believe you messed this up, fix it now!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so thrilled, my team just nailed the presentation!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'Why does this keep failing, itâ€™s driving me nuts!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'I feel so lost, nothing makes sense anymore.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Hey, can you set an alarm for 7 AM tomorrow?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.40)\n",
      "\n",
      "Sentence: 'You gotta be kidding me, this is the worst service ever!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'what is ml?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.52)\n",
      "\n",
      "Sentence: 'This system is a complete disaster, get it fixed!'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.96)\n",
      "\n",
      "Sentence: 'This system is a complete disaster, get it fixed!'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.96)\n",
      "\n",
      "Sentence: '\"I canâ€™t believe how amazing this party is, best night ever!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.97)\n",
      "\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.92)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'This is absolutely unacceptable, do better!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Can you explain how neural networks work?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m having the worst day ever, nothing is going right.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.87)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'What the heck is wrong with this thing, itâ€™s broken again!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Tell me about the latest AI advancements.'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.47)\n",
      "\n",
      "Sentence: 'I canâ€™t believe you messed this up, fix it now!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so thrilled, my team just nailed the presentation!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'Why does this keep failing, itâ€™s driving me nuts!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'I feel so lost, nothing makes sense anymore.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Hey, can you set an alarm for 7 AM tomorrow?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.40)\n",
      "\n",
      "Sentence: 'You gotta be kidding me, this is the worst service ever!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Why does this app keep crashing, itâ€™s so annoying!'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.98)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load both emotion classifiers\n",
    "anger_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "other_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    top_k=None,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean WebRTC transcription text by adding punctuation, removing filler words, and normalizing.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\b(um|uh|like|you know)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    # Add punctuation for run-on sentences and negative questions\n",
    "    text = re.sub(r'\\b(why isn\\'t|what the|are you serious|come on|i did not|this is ridiculous|you kidding|fix it|do better|unacceptable|driving me nuts|broken again|worst service)\\b', r'\\1.', text)\n",
    "    text = re.sub(r'\\b(this what|what you)\\b', r'\\1,', text)\n",
    "    text = text.replace(' i ', ' I ')\n",
    "    if not text.endswith('.'):\n",
    "        text += '.'\n",
    "    return text\n",
    "\n",
    "def is_neutral_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for neutral queries, excluding emotionally charged questions.\n",
    "    \"\"\"\n",
    "    neutral_patterns = [\n",
    "        r'^(what|how|when|where|can you|could you|tell me|is it).*?\\?$',\n",
    "        r'^(please|could you|would you).*?(schedule|set|find|look up|tell me|explain).*'\n",
    "    ]\n",
    "    technical_terms = ['machine learning', 'deep learning', 'artificial intelligence', 'data science', 'neural networks']\n",
    "    negative_words = ['not', 'isn\\'t', 'doesn\\'t', 'won\\'t', 'can\\'t', 'serious', 'ridiculous', 'failing', 'broken']\n",
    "    text = text.lower().strip()\n",
    "    # Mark as neutral if it contains technical terms\n",
    "    if any(term in text for term in technical_terms):\n",
    "        return True\n",
    "    # Exclude questions with negative/emotional words\n",
    "    if any(word in text for word in negative_words):\n",
    "        return False\n",
    "    return any(re.match(pattern, text) for pattern in neutral_patterns)\n",
    "\n",
    "def is_anger_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for anger-related queries or statements.\n",
    "    \"\"\"\n",
    "    anger_patterns = [\n",
    "        r'\\b(why isn\\'t|what the|are you serious|come on|i did not expect|this is ridiculous|you kidding|fix it|do better|unacceptable|driving me nuts|broken again|worst service)\\b',\n",
    "        r'\\b(not working|failing|broken|messed up)\\b'\n",
    "    ]\n",
    "    text = text.lower().strip()\n",
    "    return any(re.search(pattern, text) for pattern in anger_patterns)\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    \"\"\"\n",
    "    Predict emotion using j-hartmann for anger and cardiffnlp for other emotions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the input text\n",
    "        text = clean_text(text)\n",
    "        if not text:\n",
    "            raise ValueError(\"Input text is empty after cleaning\")\n",
    "\n",
    "        # Check for neutral queries\n",
    "        if is_neutral_query(text):\n",
    "            return \"Neutral\", 0.95\n",
    "\n",
    "        # Check for anger queries (rule-based)\n",
    "        if is_anger_query(text):\n",
    "            return \"Anger\", 0.90\n",
    "\n",
    "        # Check for anger using j-hartmann model\n",
    "        anger_results = anger_classifier(text)[0]\n",
    "        anger_score = next((r['score'] for r in anger_results if r['label'] == 'anger'), 0.0)\n",
    "        if anger_score > 0.7:\n",
    "            return \"Anger\", anger_score\n",
    "\n",
    "        # Use cardiffnlp for other emotions\n",
    "        other_results = other_classifier(text)[0]\n",
    "        \n",
    "        # Suppress joy for negative sentences\n",
    "        negative_words = ['not', 'isn\\'t', 'doesn\\'t', 'won\\'t', 'can\\'t', 'failing', 'broken']\n",
    "        if any(word in text.lower() for word in negative_words):\n",
    "            for result in other_results:\n",
    "                if result['label'] == 'emotion:joy':\n",
    "                    result['score'] *= 0.1  # Reduce joy score significantly\n",
    "\n",
    "        # Find the emotion with the highest score\n",
    "        best = max(other_results, key=lambda x: x['score'])\n",
    "        emotion = best['label'].replace('emotion:', '').capitalize()\n",
    "        score = best['score']\n",
    "\n",
    "        # Fallback to Neutral if confidence is low\n",
    "        if score < 0.7:\n",
    "            return \"Neutral\", score\n",
    "\n",
    "        return emotion, score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test sentences from previous output plus new ones\n",
    "    test_sentences = [\n",
    "        \"I donâ€™t care how good you are, just get it done!\",\n",
    "        \"What is machine learning?\",\n",
    "        \"Iâ€™m so excited for the concert tonight!\",\n",
    "        \"Why isnâ€™t this working properly?\",\n",
    "        \"Iâ€™m feeling really down today.\",\n",
    "        \"Could you please schedule a meeting for next week?\",\n",
    "        \"What is deep learning?\",\n",
    "        \"Are you serious this what you are giving me come on i did not expected that from you\",\n",
    "        \"This is absolutely unacceptable, do better!\",\n",
    "        \"Can you explain how neural networks work?\",\n",
    "        \"Iâ€™m having the worst day ever, nothing is going right.\",\n",
    "        \"Wow, I just won a free trip, this is awesome!\",\n",
    "        \"What the heck is wrong with this thing, itâ€™s broken again!\",\n",
    "        \"Tell me about the latest AI advancements.\",\n",
    "        \"I canâ€™t believe you messed this up, fix it now!\",\n",
    "        \"Iâ€™m so thrilled, my team just nailed the presentation!\",\n",
    "        \"Why does this keep failing, itâ€™s driving me nuts!\",\n",
    "        \"I feel so lost, nothing makes sense anymore.\",\n",
    "        \"Hey, can you set an alarm for 7 AM tomorrow?\",\n",
    "        \"You gotta be kidding me, this is the worst service ever!\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing emotion detection with example sentences (type 'exit' to quit).\")\n",
    "    print(\"Enter your own transcript or press Enter to test predefined sentences.\")\n",
    "    \n",
    "    while True:\n",
    "        transcript = input(\"Transcript: \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        if not transcript.strip():\n",
    "            print(\"\\nTesting predefined sentences:\")\n",
    "            for sentence in test_sentences:\n",
    "                emotion, score = predict_emotion_from_text(sentence)\n",
    "                print(f\"Sentence: '{sentence}'\")\n",
    "                print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "        else:\n",
    "            emotion, score = predict_emotion_from_text(transcript)\n",
    "            print(f\"Sentence: '{transcript}'\")\n",
    "            print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0520 12:00:21.309000 29156 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing emotion detection with example sentences (type 'exit' to quit).\n",
      "Enter your own transcript or press Enter to test predefined sentences.\n",
      "\n",
      "Testing predefined sentences:\n",
      "Sentence: 'I donâ€™t care how good you are, just get it done!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.92)\n",
      "\n",
      "Sentence: 'What is machine learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m so excited for the concert tonight!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why isnâ€™t this working properly?'\n",
      "âœ… Predicted emotion: Joy (confidence: 0.89)\n",
      "\n",
      "Sentence: 'Iâ€™m feeling really down today.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Could you please schedule a meeting for next week?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'What is deep learning?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Are you serious this what you are giving me come on i did not expected that from you'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'This is absolutely unacceptable, do better!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Can you explain how neural networks work?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Iâ€™m having the worst day ever, nothing is going right.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.87)\n",
      "\n",
      "Sentence: 'Wow, I just won a free trip, this is awesome!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.94)\n",
      "\n",
      "Sentence: 'What the heck is wrong with this thing, itâ€™s broken again!'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Tell me about the latest AI advancements.'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'I canâ€™t believe you messed this up, fix it now!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'Iâ€™m so thrilled, my team just nailed the presentation!'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'Why does this keep failing, itâ€™s driving me nuts!'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'I feel so lost, nothing makes sense anymore.'\n",
      "âœ… Predicted emotion: Sadness (confidence: 0.98)\n",
      "\n",
      "Sentence: 'Hey, can you set an alarm for 7 AM tomorrow?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'You gotta be kidding me, this is the worst service ever!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'what is ml?'\n",
      "âœ… Predicted emotion: Neutral (confidence: 0.95)\n",
      "\n",
      "Sentence: 'This system is a complete disaster, get it fixed!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n",
      "Sentence: 'I canâ€™t believe how amazing this party is, best night ever!'\n",
      "âœ… Predicted emotion: Optimism (confidence: 0.97)\n",
      "\n",
      "Sentence: 'Why does this app keep crashing, itâ€™s so annoying!'\n",
      "âœ… Predicted emotion: Anger (confidence: 0.90)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "# Load both emotion classifiers\n",
    "anger_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "other_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    top_k=None,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean WebRTC transcription text by adding punctuation, removing filler words, and normalizing.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\b(um|uh|like|you know)\\b', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    # Add punctuation for run-on sentences and negative questions\n",
    "    text = re.sub(r'\\b(why isn\\'t|what the|are you serious|come on|i did not|this is ridiculous|you kidding|fix it|do better|unacceptable|driving me nuts|broken again|worst service|keep crashing|complete disaster|so annoying|totally unacceptable|fed up|nonsense)\\b', r'\\1.', text)\n",
    "    text = re.sub(r'\\b(this what|what you)\\b', r'\\1,', text)\n",
    "    text = text.replace(' i ', ' I ')\n",
    "    if not text.endswith('.'):\n",
    "        text += '.'\n",
    "    return text\n",
    "\n",
    "def is_neutral_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for neutral queries, ensuring high confidence.\n",
    "    \"\"\"\n",
    "    neutral_patterns = [\n",
    "        r'^(what|how|when|where|can you|could you|tell me|is it|hey).*?\\?$',\n",
    "        r'^(please|could you|would you|hey).*?(schedule|set|find|look up|tell me|explain|reset|alarm).*'\n",
    "    ]\n",
    "    technical_terms = ['machine learning', 'deep learning', 'artificial intelligence', 'data science', 'neural networks', 'ml', 'ai', 'advancements']\n",
    "    text = text.lower().strip()\n",
    "    # Mark as neutral if it contains technical terms or neutral patterns\n",
    "    if any(term in text for term in technical_terms) or any(re.match(pattern, text) for pattern in neutral_patterns):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_anger_query(text):\n",
    "    \"\"\"\n",
    "    Rule-based check for anger-related queries or statements.\n",
    "    \"\"\"\n",
    "    anger_patterns = [\n",
    "        r'\\b(why isn\\'t|what the|are you serious|come on|i did not expect|this is ridiculous|you kidding|fix it|do better|unacceptable|driving me nuts|broken again|worst service|keep crashing|complete disaster|so annoying|totally unacceptable|fed up|nonsense|not working|failing|broken|messed up)\\b'\n",
    "    ]\n",
    "    text = text.lower().strip()\n",
    "    return any(re.search(pattern, text) for pattern in anger_patterns)\n",
    "\n",
    "def predict_emotion_from_text(text):\n",
    "    \"\"\"\n",
    "    Predict emotion using j-hartmann for anger and cardiffnlp for other emotions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean the input text\n",
    "        text = clean_text(text)\n",
    "        if not text:\n",
    "            raise ValueError(\"Input text is empty after cleaning\")\n",
    "\n",
    "        # Check for neutral queries\n",
    "        if is_neutral_query(text):\n",
    "            return \"Neutral\", 0.95\n",
    "\n",
    "        # Check for anger queries (rule-based)\n",
    "        if is_anger_query(text):\n",
    "            return \"Anger\", 0.90\n",
    "\n",
    "        # Check for anger using j-hartmann model\n",
    "        anger_results = anger_classifier(text)[0]\n",
    "        anger_score = next((r['score'] for r in anger_results if r['label'] == 'anger'), 0.0)\n",
    "        if anger_score > 0.6:  # Lowered threshold for better anger detection\n",
    "            return \"Anger\", anger_score\n",
    "\n",
    "        # Use cardiffnlp for other emotions\n",
    "        other_results = other_classifier(text)[0]\n",
    "        \n",
    "        # Suppress joy for negative sentences\n",
    "        negative_words = ['not', 'isn\\'t', 'doesn\\'t', 'won\\'t', 'can\\'t', 'failing', 'broken', 'crashing', 'annoying', 'disaster', 'unacceptable', 'fed up', 'nonsense']\n",
    "        if any(word in text.lower() for word in negative_words):\n",
    "            for result in other_results:\n",
    "                if result['label'] == 'emotion:joy':\n",
    "                    result['score'] *= 0.05  # Stronger joy suppression\n",
    "\n",
    "        # Find the emotion with the highest score\n",
    "        best = max(other_results, key=lambda x: x['score'])\n",
    "        emotion = best['label'].replace('emotion:', '').capitalize()\n",
    "        score = best['score']\n",
    "\n",
    "        # Fallback to Neutral if confidence is low\n",
    "        if score < 0.7:\n",
    "            return \"Neutral\", 0.95\n",
    "\n",
    "        return emotion, score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Deduplicated test sentences, including new ones\n",
    "    test_sentences = [\n",
    "        \"I donâ€™t care how good you are, just get it done!\",\n",
    "        \"What is machine learning?\",\n",
    "        \"Iâ€™m so excited for the concert tonight!\",\n",
    "        \"Why isnâ€™t this working properly?\",\n",
    "        \"Iâ€™m feeling really down today.\",\n",
    "        \"Could you please schedule a meeting for next week?\",\n",
    "        \"What is deep learning?\",\n",
    "        \"Are you serious this what you are giving me come on i did not expected that from you\",\n",
    "        \"This is absolutely unacceptable, do better!\",\n",
    "        \"Can you explain how neural networks work?\",\n",
    "        \"Iâ€™m having the worst day ever, nothing is going right.\",\n",
    "        \"Wow, I just won a free trip, this is awesome!\",\n",
    "        \"What the heck is wrong with this thing, itâ€™s broken again!\",\n",
    "        \"Tell me about the latest AI advancements.\",\n",
    "        \"I canâ€™t believe you messed this up, fix it now!\",\n",
    "        \"Iâ€™m so thrilled, my team just nailed the presentation!\",\n",
    "        \"Why does this keep failing, itâ€™s driving me nuts!\",\n",
    "        \"I feel so lost, nothing makes sense anymore.\",\n",
    "        \"Hey, can you set an alarm for 7 AM tomorrow?\",\n",
    "        \"You gotta be kidding me, this is the worst service ever!\",\n",
    "        \"what is ml?\",\n",
    "        \"This system is a complete disaster, get it fixed!\",\n",
    "        \"I canâ€™t believe how amazing this party is, best night ever!\",\n",
    "        \"Why does this app keep crashing, itâ€™s so annoying!\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing emotion detection with example sentences (type 'exit' to quit).\")\n",
    "    print(\"Enter your own transcript or press Enter to test predefined sentences.\")\n",
    "    \n",
    "    while True:\n",
    "        transcript = input(\"Transcript: \")\n",
    "        if transcript.lower() == 'exit':\n",
    "            break\n",
    "        if not transcript.strip():\n",
    "            print(\"\\nTesting predefined sentences:\")\n",
    "            for sentence in test_sentences:\n",
    "                emotion, score = predict_emotion_from_text(sentence)\n",
    "                print(f\"Sentence: '{sentence}'\")\n",
    "                print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")\n",
    "        else:\n",
    "            emotion, score = predict_emotion_from_text(transcript)\n",
    "            print(f\"Sentence: '{transcript}'\")\n",
    "            print(f\"âœ… Predicted emotion: {emotion} (confidence: {score:.2f})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
